{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A WebsiteData object to make code generaizable and easier to use with just URL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "\n",
    "class WebsiteData:\n",
    "    name = \"\"\n",
    "    URL = \"\"\n",
    "    links = []\n",
    "    nodeParameters = []\n",
    "    keyValueLists  = []\n",
    "    JsonNode = {}\n",
    "    soup = None\n",
    "    \n",
    "    def __init__(self, url, nodeParams, keyValues):\n",
    "        html_page = urllib.request.urlopen(url)\n",
    "        self.soup = BeautifulSoup(html_page, \"lxml\")\n",
    "        self.URL = self.__getUsefulParentURL(url)\n",
    "        self.links = self.__getUsefulLinks()\n",
    "        self.nodeParameters = self.nodeParams\n",
    "        self.keyValueLists = self.keyValues\n",
    "            \n",
    "    #Need to adjust parent URL to ensure that it can be used to filter the links in the page\n",
    "    def __getUsefulParentURL(self, parentURL):\n",
    "        #list of possible correct endings for the parentURL\n",
    "        possibleParentEnds = ['.org', '.edu', '.com']\n",
    "    \n",
    "        for end in possibleParentEnds:\n",
    "            #attempts to split parentURL by one of the endings\n",
    "            parentURLSplit = parentURL.split(end)\n",
    "        \n",
    "            #if the split is successful then the parentURL is reassigned to the string before the split + the ending\n",
    "            if len(parentURLSplit) > 1:\n",
    "                parentURL = parentURLSplit[0] + end\n",
    "                return parentURL\n",
    "            \n",
    "    #Finds all links in the page that are within the website and not malformed by ensuring the parentURL is in the URL.\n",
    "    def __getUsefulLinks(self):\n",
    "        links = []\n",
    "    \n",
    "        if self.soup.find_all('a') != None:\n",
    "            for link in self.soup.find_all('a'):\n",
    "                if link != None and link.get('href') != None and URL in link.get('href'):\n",
    "                    #print(link.get('href'))\n",
    "                    links.append(link.get('href'))\n",
    "        \n",
    "        links.append(self.URL)\n",
    "        return links\n",
    "\n",
    "    #Utilizes a BeautifulSoup object (soup) to scrape all text that contains the given keyword. Filters for certain tags and does\n",
    "    #not take text from solely header (h) tags, instead takes text from next filtered tag after the header. Returns \n",
    "    def __keyWordScraper(self, soup, keyWord):\n",
    "        searchTxt = ''\n",
    "        correctName = ['p', 'li', 'table']\n",
    "        tagList = self.__findTags(soup, keyWord)\n",
    "    \n",
    "        #This loop goes through each tag and rips the text from that tag. If that tag is a header, then the text from the next \n",
    "        #useful tag is ripped instead. All text is saved in searchTxt\n",
    "        for tag in tagLst:\n",
    "            if 'h' in tag.name:\n",
    "                typeTag = type(soup.find('li'))\n",
    "                current = tag.next_sibling\n",
    "                while current != None and  not isinstance(current, typeTag) and current.name not in correctName:\n",
    "                    current = current.next_sibling\n",
    "                if current != None:\n",
    "                    searchTxt = searchTxt + current.text\n",
    "            else:\n",
    "                if(tag.name in correctName):\n",
    "                    searchTxt = searchTxt + tag.text\n",
    "                \n",
    "        return searchTxt\n",
    "    \n",
    "    #Finds all tags within a BeautifulSoup object that's text contains a certain keyword and returns a list of these tags.\n",
    "    def __findTags(self, soup, keyword):\n",
    "        tagList = []\n",
    "        \n",
    "        for elem in soup(text=re.compile(keyWord)):\n",
    "            tagList.append(elem.parent)\n",
    "            \n",
    "        return tagList\n",
    "    \n",
    "    #Applies the keyWordScraper function to a BeautifulSoup object(soup) for a list of keywords. Returns the text found.\n",
    "    def __mapKeywordScraper(self, keyWords, soup):\n",
    "        foundTxt = ''\n",
    "    \n",
    "        for keyWord in keyWords:\n",
    "            foundTxt = foundTxt + self.__keyWordScraper(soup, keyWord)\n",
    "    \n",
    "        return foundTxt\n",
    "    \n",
    "    #this method takes a list of links and applies the scraping method to that list. \n",
    "    #WARNING: this method may take a while since it goes through every link, give it time to run before terminating it.\n",
    "    def __mapURLs(self, keywords):\n",
    "        foundTxt = ''\n",
    "        for link in links:\n",
    "            new_page = urllib.request.urlopen(link)\n",
    "            new_soup = BeautifulSoup(new_page, \"lxml\")\n",
    "            foundTxt = foundTxt + __mapKeywordScraper(keywords, new_soup)\n",
    "        return foundTxt\n",
    "    \n",
    "    #creates JSON object\n",
    "    def __createJsonNode(self):\n",
    "        for x in range(0, len(keyValueLists)):\n",
    "            school[nodeParameters[x]] += [self.__mapURLs(keyValueLists[x])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
